{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distinct-olympus",
   "metadata": {},
   "source": [
    "# Movie Recommendation System\n",
    "Im Folgenden wird ausführlich erläutert, wie im Rahmen der Vorlesung 'Machine Learning' ein Movie-Recommendation-System entworfen worden ist, aber auch welche Ansätze fehlgeschlagen und welche Fehler und Probleme aufgetreten sind.\n",
    "### Datensätze\n",
    "First things first: Um eine Grundlage für ein System zu schaffen, welches Vorschläge bezüglich Filmen schaffen soll, bedarf es einer gewissen Menge an Daten. Es folgt ein kleiner Überblick zu den verfügbaren Daten, aus welchen dann die relevanten ausgewählt worden sind.\n",
    "\n",
    "| Movies | Credits | Ratings |\n",
    "| --- | --- | --- |\n",
    "| Movie ID | Movie ID | Movie ID |\n",
    "| Title | Cast | User ID |\n",
    "| Genres | Crew | Rating |\n",
    "| Year |  | Timestamp |\n",
    "| Languages |\n",
    "| Popularity |\n",
    "| Runtime |\n",
    "| Vote Count (IMDB) |\n",
    "| Vote Average |\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Die erste Idee\n",
    "\n",
    "Ein bekannter Ansatz bei Recommendation-Systemen ist das sogenannte __Collaborative-filtering__. Grundlegend basiert dieses darauf, dann Nutzer, welche in der Vergangenheit ähnliche Muster aufgewiesen, diese auch in der Zukunft aufweisen werden.<br>\n",
    "In unserem Fall könnten wir also für einen gegebenen Nutzer, passende zugehörige Nutzer finden, welche in der Vergangenheit die gleichen Filme ähnlich bewertet haben. Problematisch ist jedoch, dass der Geschmack der Nutzer sich im Verlauf der Zeit jedoch ändern und somit unser Ergebnis verfälschen. Anstelle dessen werden wir im folgenden die Ähnlichkeit eines Films mit Filmen, die von einem Nutzer bereits bewertet hat feststellen und anhand dieser eine Vorhersage abgeben. <br>\n",
    "Methoden zum Bestimmen der Ähnlichkeit zweier Filme sind beispielsweise die __Pearson-Korrelation__ oder __Kosinus-Ähnlichkeit__.<br>\n",
    "Ein bekanntes Probem hierbei stellt jedoch der Mangel an Skalierbarkeit und Sparsamkeit dar, da der Rechenaufwand mit Nutzern und auch Filmen steigen wird. Um dieses Problem zu lösen, wird ein latentes Variablenmodell genutzt um den Zusammenhang zwischen Nutzern und Filmen festzustellen. Anders ausgedrückt: Wir konzentrieren uns auf einen zu betrachtenden Faktor und bringen Filme und Nutzer auf die selbe Dimension um so den Zusammenhang dieser besser zu verstehen. Dies wird auch __Singular Value Decomposition__. Dadurch machen wir aus unserem Recommendation-Problem ein Optimierungs-Problem machen und können mit dem __RMSE__ eine Bewertung aufstellen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-injury",
   "metadata": {},
   "source": [
    "# Datenimport\n",
    "Anhand der eben beschriebenen Idee, stellt man fest, dass für diese Art eines Modells nur die Rating-Daten nötig sind, denn außer der Movie-ID muss der Computer nichts über den Film selber wissen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "opening-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('movie_data/ratings_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-research",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "Die Library __surprise__ gibt uns die nötige Funktion zur Singular Value Decomposition und einen Reader, welcher dazu dient Ratings zu konvertieren. Ebenfalls gibt es und die Funktion Datasets aus Pandas Dataframes zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "placed-serial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.89122487, 0.89993953, 0.89916626, 0.89369484, 0.89863653]),\n",
       " 'test_mae': array([0.68673109, 0.69253091, 0.69356544, 0.68931726, 0.69205333]),\n",
       " 'fit_time': (6.678909063339233,\n",
       "  6.579374074935913,\n",
       "  6.739435195922852,\n",
       "  6.6382896900177,\n",
       "  6.335058927536011),\n",
       " 'test_time': (0.1655576229095459,\n",
       "  0.17256999015808105,\n",
       "  0.16954851150512695,\n",
       "  0.17253923416137695,\n",
       "  0.18454408645629883)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "svd = SVD()\n",
    "cross_validate(svd, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-constant",
   "metadata": {},
   "source": [
    "Anhand dieser Ausgabe können wir erkennen, dass wir einen durchschnittlichen RMSE von 0.89 haben, was sich als sehr gut erweist. Als nächstes wollen wir nun endlich ein Modell trainieren und Vorhersagen treffen. <br>\n",
    "Auch hierbei kommt und die __surprise__ library zu gunsten. Über die Methode build_full_trainset können wir aus unserem eben definierten Dataset ein Trainingset definieren. Anhand dieses Trainingssatz können wir mit svd-Modell nun auch Vorhersagen treffen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "manual-staff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=1, iid=302, r_ui=3, est=2.6617475877384873, details={'was_impossible': False})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "# Vorhersage für den Nutzer mit der ID 1 und für den Film mit der ID 302\n",
    "svd.predict(1, 302, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-growth",
   "metadata": {},
   "source": [
    "__est__ beschreibt hier also die erwartete Bewertung. Nicht schlecht!<br>\n",
    "### Die Alternative\n",
    "An diesem Punkt haben wir uns als Gruppe jedoch entschieden, dass diese Alternative nicht ganz unserer Idee entspricht. Wir wollen etwas mehr Praxis in dieses Projekt bringen und auch in der Lage sein, Vorschläge für uns selber bekommen zu können, nicht nur für IDs in einem Datensatz. <br>\n",
    "#### Die Idee\n",
    "Eine App in welcher man mehrere Filme auswählen kann und anhand dieser Auswahl Vorschläge bekommt.\n",
    "#### Der Ansatz\n",
    "Neben dem Collaborative-Filtering ist einer der typischen Ansätze bei Recommendation-Systemen das Content-based-Filtering. Hierbei werden Ähnlichkeiten zwischen Filmen direkt gesucht und dann als Vorschlag geliefert. Es werden so zwar keine Informationen über den Nutzer einbezogen, jedoch kann dadurch ausgeglichen werden, dass der Nutzer sich ja Filme aussuchen kann, für welche er Vorschläge bekommen will.\n",
    "#### Der Input\n",
    "Festzulegen war, welche Informationen über einen Film wirklich relevant sind, um einen Vorschlag zu machen. Entschlossen haben wir uns als Gruppe auf folgende Informationen:\n",
    "- Genres\n",
    "- Schauspieler\n",
    "- Regisseur\n",
    "- Grundlegender Plot ( Keywords aus weiterem File )\n",
    "\n",
    "Um diese Informationen gut verwenden zu können ist jedoch einiges an Datenaufbereitung nötig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "impressed-occurrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46414</th>\n",
       "      <td>439050</td>\n",
       "      <td>[{'id': 10703, 'name': 'tragic love'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46415</th>\n",
       "      <td>111109</td>\n",
       "      <td>[{'id': 2679, 'name': 'artist'}, {'id': 14531,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46416</th>\n",
       "      <td>67758</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46417</th>\n",
       "      <td>227506</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46418</th>\n",
       "      <td>461257</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46419 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           keywords\n",
       "0         862  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...\n",
       "1        8844  [{'id': 10090, 'name': 'board game'}, {'id': 1...\n",
       "2       15602  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...\n",
       "3       31357  [{'id': 818, 'name': 'based on novel'}, {'id':...\n",
       "4       11862  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...\n",
       "...       ...                                                ...\n",
       "46414  439050             [{'id': 10703, 'name': 'tragic love'}]\n",
       "46415  111109  [{'id': 2679, 'name': 'artist'}, {'id': 14531,...\n",
       "46416   67758                                                 []\n",
       "46417  227506                                                 []\n",
       "46418  461257                                                 []\n",
       "\n",
       "[46419 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# movies = pd.read_csv(\"movie_data/movies_metadata.csv\", low_memory=False)\n",
    "# movie_actors = pd.read_csv(\"movie_data/credits.csv\", low_memory=False)\n",
    "# keywords = pd.read_csv(\"movie_data/keywords.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-surname",
   "metadata": {},
   "source": [
    "# Datensätze verbinden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "otherwise-bleeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-08-20</th>\n",
       "      <td>- Written by Ørnås</td>\n",
       "      <td>0.065736</td>\n",
       "      <td>/ff9qCepilowshEtG2GYWwzt2bs4.jpg</td>\n",
       "      <td>[{'name': 'Carousel Productions', 'id': 11176}...</td>\n",
       "      <td>[{'iso_3166_1': 'CA', 'name': 'Canada'}, {'iso...</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-29</th>\n",
       "      <td>Rune Balot goes to a casino connected to the ...</td>\n",
       "      <td>1.931659</td>\n",
       "      <td>/zV8bHuSL6WXoD6FWogP9j4x80bL.jpg</td>\n",
       "      <td>[{'name': 'Aniplex', 'id': 2883}, {'name': 'Go...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>[{'iso_639_1': 'ja', 'name': '日本語'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>Avalanche Sharks tells the story of a bikini ...</td>\n",
       "      <td>2.185485</td>\n",
       "      <td>/zaSf5OG7V8X8gqFvly88zDdRm46.jpg</td>\n",
       "      <td>[{'name': 'Odyssey Media', 'id': 17161}, {'nam...</td>\n",
       "      <td>[{'iso_3166_1': 'CA', 'name': 'Canada'}]</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Beware Of Frost Bites</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401840</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt3291632</td>\n",
       "      <td>es</td>\n",
       "      <td>School's out</td>\n",
       "      <td>Two high school kids mentored by a nightclub o...</td>\n",
       "      <td>0.207775</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>School's out</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        adult  \\\n",
       "id                                                              \n",
       "1997-08-20                                 - Written by Ørnås   \n",
       "2012-09-29   Rune Balot goes to a casino connected to the ...   \n",
       "2014-01-01   Avalanche Sharks tells the story of a bikini ...   \n",
       "401840                                                  False   \n",
       "\n",
       "           belongs_to_collection                            budget  \\\n",
       "id                                                                   \n",
       "1997-08-20              0.065736  /ff9qCepilowshEtG2GYWwzt2bs4.jpg   \n",
       "2012-09-29              1.931659  /zV8bHuSL6WXoD6FWogP9j4x80bL.jpg   \n",
       "2014-01-01              2.185485  /zaSf5OG7V8X8gqFvly88zDdRm46.jpg   \n",
       "401840                       NaN                                 0   \n",
       "\n",
       "                                                       genres  \\\n",
       "id                                                              \n",
       "1997-08-20  [{'name': 'Carousel Productions', 'id': 11176}...   \n",
       "2012-09-29  [{'name': 'Aniplex', 'id': 2883}, {'name': 'Go...   \n",
       "2014-01-01  [{'name': 'Odyssey Media', 'id': 17161}, {'nam...   \n",
       "401840                                                     []   \n",
       "\n",
       "                                                     homepage    imdb_id  \\\n",
       "id                                                                         \n",
       "1997-08-20  [{'iso_3166_1': 'CA', 'name': 'Canada'}, {'iso...          0   \n",
       "2012-09-29  [{'iso_3166_1': 'US', 'name': 'United States o...          0   \n",
       "2014-01-01           [{'iso_3166_1': 'CA', 'name': 'Canada'}]          0   \n",
       "401840                                                    NaN  tt3291632   \n",
       "\n",
       "           original_language                            original_title  \\\n",
       "id                                                                       \n",
       "1997-08-20             104.0  [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "2012-09-29              68.0      [{'iso_639_1': 'ja', 'name': '日本語'}]   \n",
       "2014-01-01              82.0  [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "401840                    es                              School's out   \n",
       "\n",
       "                                                     overview  \\\n",
       "id                                                              \n",
       "1997-08-20                                           Released   \n",
       "2012-09-29                                           Released   \n",
       "2014-01-01                                           Released   \n",
       "401840      Two high school kids mentored by a nightclub o...   \n",
       "\n",
       "                       popularity  ... spoken_languages    status tagline  \\\n",
       "id                                 ...                                      \n",
       "1997-08-20                    NaN  ...              NaN       NaN     NaN   \n",
       "2012-09-29                    NaN  ...              NaN       NaN     NaN   \n",
       "2014-01-01  Beware Of Frost Bites  ...              NaN       NaN     NaN   \n",
       "401840                   0.207775  ...               []  Released     NaN   \n",
       "\n",
       "                   title  video  vote_average vote_count cast crew keywords  \n",
       "id                                                                           \n",
       "1997-08-20           NaN    NaN           NaN        NaN  NaN  NaN      NaN  \n",
       "2012-09-29           NaN    NaN           NaN        NaN  NaN  NaN      NaN  \n",
       "2014-01-01           NaN    NaN           NaN        NaN  NaN  NaN      NaN  \n",
       "401840      School's out  False           0.0        0.0  NaN  NaN      NaN  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join movies / credits and keywords on index, which has to be a string\n",
    "movie_actors['id'] = movie_actors['id'].apply(str)\n",
    "keywords['id'] = keywords['id'].apply(str)\n",
    "merged = movies.set_index(\"id\").join(movie_actors.set_index('id')).join(keywords.set_index('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-coordination",
   "metadata": {},
   "source": [
    "# Datenaufbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "incomplete-tuner",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tf_genres</th>\n",
       "      <th>tf_cast</th>\n",
       "      <th>director</th>\n",
       "      <th>tf_keywords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Lock, Stock and Two Smoking Barrels</td>\n",
       "      <td>[Comedy, Crime]</td>\n",
       "      <td>[Jason Flemyng, Dexter Fletcher, Nick Moran, J...</td>\n",
       "      <td>Guy Ritchie</td>\n",
       "      <td>[ambush, alcohol, shotgun, tea, joint, machism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>La estrategia del caracol</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Sergio Cabrera</td>\n",
       "      <td>[roommate, pastor, squatter, anarchist, house,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Young Einstein</td>\n",
       "      <td>[Comedy, Science Fiction]</td>\n",
       "      <td>[Yahoo Serious, Odile Le Clezio, Peewee Wilson...</td>\n",
       "      <td>Yahoo Serious</td>\n",
       "      <td>[atomic bomb, nobel prize, rock, albert einste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100010</th>\n",
       "      <td>Flight Command</td>\n",
       "      <td>[Drama, War]</td>\n",
       "      <td>[Robert Taylor, Ruth Hussey, Walter Pidgeon, P...</td>\n",
       "      <td>Frank Borzage</td>\n",
       "      <td>[pilot, navy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100017</th>\n",
       "      <td>Hounded</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[Kostja Ullmann, Maren Kroymann, Moritz Grove,...</td>\n",
       "      <td>Angelina Maccarone</td>\n",
       "      <td>[fetishism, masochism, submissive, older woman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>Mona Lisa</td>\n",
       "      <td>[Drama, Crime, Romance]</td>\n",
       "      <td>[Bob Hoskins, Cathy Tyson, Michael Caine, Robb...</td>\n",
       "      <td>Neil Jordan</td>\n",
       "      <td>[london england, prostitute, ex-detainee, chau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100024</th>\n",
       "      <td>Bloodwork</td>\n",
       "      <td>[Horror, Thriller]</td>\n",
       "      <td>[Travis Van Winkle, Tricia Helfer, Eric Robert...</td>\n",
       "      <td>Eric Wostenberg</td>\n",
       "      <td>[dangerous side effects, clinical trials, alle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>The Saint</td>\n",
       "      <td>[Thriller, Action, Romance, Science Fiction, A...</td>\n",
       "      <td>[Val Kilmer, Elisabeth Shue, Rade Serbedzija, ...</td>\n",
       "      <td>Phillip Noyce</td>\n",
       "      <td>[berlin, russia, gas, master thief, the saint]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100032</th>\n",
       "      <td>The Great Los Angeles Earthquake</td>\n",
       "      <td>[Drama, Action]</td>\n",
       "      <td>[Joanna Kerns, Dan Lauria, Bonnie Bartlett, Li...</td>\n",
       "      <td>Larry Elikann</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100033</th>\n",
       "      <td>Mr. Thank You</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[Kaoru Futaba, Michiko Kuwano, Takashi Ishiyam...</td>\n",
       "      <td>Hiroshi Shimizu</td>\n",
       "      <td>[countryside]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "id                                            \n",
       "100     Lock, Stock and Two Smoking Barrels   \n",
       "10000             La estrategia del caracol   \n",
       "10001                        Young Einstein   \n",
       "100010                       Flight Command   \n",
       "100017                              Hounded   \n",
       "10002                             Mona Lisa   \n",
       "100024                            Bloodwork   \n",
       "10003                             The Saint   \n",
       "100032     The Great Los Angeles Earthquake   \n",
       "100033                        Mr. Thank You   \n",
       "\n",
       "                                                tf_genres  \\\n",
       "id                                                          \n",
       "100                                       [Comedy, Crime]   \n",
       "10000                                     [Comedy, Drama]   \n",
       "10001                           [Comedy, Science Fiction]   \n",
       "100010                                       [Drama, War]   \n",
       "100017                                            [Drama]   \n",
       "10002                             [Drama, Crime, Romance]   \n",
       "100024                                 [Horror, Thriller]   \n",
       "10003   [Thriller, Action, Romance, Science Fiction, A...   \n",
       "100032                                    [Drama, Action]   \n",
       "100033                                            [Drama]   \n",
       "\n",
       "                                                  tf_cast            director  \\\n",
       "id                                                                              \n",
       "100     [Jason Flemyng, Dexter Fletcher, Nick Moran, J...         Guy Ritchie   \n",
       "10000                                                  []      Sergio Cabrera   \n",
       "10001   [Yahoo Serious, Odile Le Clezio, Peewee Wilson...       Yahoo Serious   \n",
       "100010  [Robert Taylor, Ruth Hussey, Walter Pidgeon, P...       Frank Borzage   \n",
       "100017  [Kostja Ullmann, Maren Kroymann, Moritz Grove,...  Angelina Maccarone   \n",
       "10002   [Bob Hoskins, Cathy Tyson, Michael Caine, Robb...         Neil Jordan   \n",
       "100024  [Travis Van Winkle, Tricia Helfer, Eric Robert...     Eric Wostenberg   \n",
       "10003   [Val Kilmer, Elisabeth Shue, Rade Serbedzija, ...       Phillip Noyce   \n",
       "100032  [Joanna Kerns, Dan Lauria, Bonnie Bartlett, Li...       Larry Elikann   \n",
       "100033  [Kaoru Futaba, Michiko Kuwano, Takashi Ishiyam...     Hiroshi Shimizu   \n",
       "\n",
       "                                              tf_keywords  \n",
       "id                                                         \n",
       "100     [ambush, alcohol, shotgun, tea, joint, machism...  \n",
       "10000   [roommate, pastor, squatter, anarchist, house,...  \n",
       "10001   [atomic bomb, nobel prize, rock, albert einste...  \n",
       "100010                                      [pilot, navy]  \n",
       "100017  [fetishism, masochism, submissive, older woman...  \n",
       "10002   [london england, prostitute, ex-detainee, chau...  \n",
       "100024  [dangerous side effects, clinical trials, alle...  \n",
       "10003      [berlin, russia, gas, master thief, the saint]  \n",
       "100032                                                 []  \n",
       "100033                                      [countryside]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove elements without title or cast or keywords\n",
    "merged = merged[merged[\"title\"].notnull()]\n",
    "merged = merged[merged[\"cast\"].notnull()]\n",
    "merged = merged[merged[\"keywords\"].notnull()]\n",
    "\n",
    "# delete not used columns\n",
    "col_dels = [\"adult\", \"belongs_to_collection\", \"homepage\", \"imdb_id\", \"poster_path\", \"production_countries\",\n",
    "            \"tagline\", \"video\", \"original_title\", \"status\", \"original_language\", \"overview\", \"budget\",\n",
    "            \"spoken_languages\", \"production_companies\", 'release_date','vote_average','vote_count','revenue','runtime','popularity']\n",
    "for col in col_dels:\n",
    "    if col in merged.columns:\n",
    "        del merged[col]\n",
    "\n",
    "merged\n",
    "\n",
    "# transform data\n",
    "tf_genres = []\n",
    "tf_cast = []\n",
    "directors = []\n",
    "tf_keywords = []\n",
    "for index, row in merged.iterrows():\n",
    "    # genres\n",
    "    tf_genres_row = []\n",
    "    genres = eval(row[\"genres\"])\n",
    "    for genre in genres:\n",
    "        tf_genres_row.append(genre[\"name\"])\n",
    "    tf_genres.append(tf_genres_row)\n",
    "    # keywords\n",
    "    tf_key_row = []\n",
    "    keys = eval(row[\"keywords\"])\n",
    "    for k in keys:\n",
    "        tf_key_row.append(k[\"name\"])\n",
    "    tf_keywords.append(tf_key_row)\n",
    "    # cast\n",
    "    tf_cast_row = []\n",
    "    casts = eval(row[\"cast\"])\n",
    "    for cast in casts:\n",
    "        tf_cast_row.append(cast[\"name\"])\n",
    "    tf_cast.append(tf_cast_row)\n",
    "    # director\n",
    "    crew = eval(row[\"crew\"])\n",
    "    director = \"\"\n",
    "    for person in crew:\n",
    "        if person[\"job\"]==\"Director\":\n",
    "            director = person[\"name\"]\n",
    "            break\n",
    "    directors.append(director)\n",
    "\n",
    "            \n",
    "# add data to table\n",
    "merged[\"tf_genres\"] = tf_genres\n",
    "merged[\"tf_cast\"] = tf_cast\n",
    "merged[\"director\"] = directors\n",
    "merged[\"tf_keywords\"] = tf_keywords\n",
    "\n",
    "# change order of columns\n",
    "cols = ['title','tf_genres','tf_cast','director','tf_keywords']\n",
    "merged = merged[cols]\n",
    "\n",
    "merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "entitled-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# namen konvertieren => kleinbuchstaben und Leerzeichen entfernen\n",
    "def clean_names(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    elif isinstance(x, str):\n",
    "        # director\n",
    "        return str.lower(x.replace(\" \", \"\"))\n",
    "\n",
    "features = ['tf_cast', 'tf_keywords', 'director', 'tf_genres']\n",
    "\n",
    "for feature in features:\n",
    "    merged[feature] = merged[feature].apply(clean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adaptive-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle zu beachtenen Informationen werden hier aneinandergehängt und gespeichert\n",
    "def create_summary(x):\n",
    "    return ' '.join(x['tf_keywords']) + ' ' + ' '.join(x['tf_cast']) + ' ' + x['director'] + ' ' + ' '.join(x['tf_genres'])\n",
    "\n",
    "merged[\"summary\"] = merged.apply(create_summary, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-certificate",
   "metadata": {},
   "source": [
    "## Count Vectorizer\n",
    "Durch das Nutzen des Count Vectorizers ist es uns möglich unsere erzeugten Text-Zusammenfassung in Verbindung zu setzen und eine Count-Matrix zu erstellen. Dies ist eine Matrix sogenannter Token Count, also einzelner Teilbegriffe innerhalb eines Strings. <br>\n",
    "Anhand dieser Matrix können wir nun durch __fit_transform__ die erkannten Tokens zu einer Document-Term-Matrix machen, welche die Häufigkeit dieser Begriffe verarbeitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "diverse-tooth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x27693 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45117 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(merged.head(2000)['summary'])\n",
    "\n",
    "count_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-spectrum",
   "metadata": {},
   "source": [
    "## Finale!!\n",
    "Anhand der hier erstellten Matrix können wir die bereits beschriebene __Kosinus-Ähnlichkeit__ Methode anwenden, um die Ähnlichkeit verschiedener Filme zu realisieren und so Vorschläge zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "perceived-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kosinus-Ähnlichkeit matrix erstellen\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "confident-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# der index wird zurück gesetzt, so dass im folgenden dieser als spalte erreichbar ist\n",
    "merged = merged.reset_index()\n",
    "indices = pd.Series(merged.index, index=merged['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "massive-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für einen Film wird hier also geschaut, welche Filme die meisten Ähnlichkeiten haben und diese werden ausgegeben\n",
    "def get_recommendations(title, cosine_sim):\n",
    "    # Passenden Index zum Filmtitel holen\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Aus der Kosinus-Ähnlichkeit für den Index die passenden Werte holen\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Nach größter Ähnlichkeit sortieren\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Auf Top-10 reduzieren\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Indices für die Top-10\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # ID der passenden Indices zurückgeben (ID ist nicht mehr Index des DF)\n",
    "    return merged['id'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "quality-mirror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thor\n",
      "Captain America: The Winter Soldier\n",
      "Ant-Man\n",
      "Captain America\n",
      "Atom Man vs Superman\n",
      "The Golden Bat\n",
      "Spawn\n",
      "Rules of Engagement\n",
      "The Book of Fate\n",
      "The incredible Paris Incident\n"
     ]
    }
   ],
   "source": [
    "res = get_recommendations('Iron Man 2', cosine_sim)\n",
    "# Beispielhaftes Ausgeben der Vorschläge mit Titel\n",
    "for id in res.values:\n",
    "    print(merged[merged[\"id\"]==id][\"title\"].values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
